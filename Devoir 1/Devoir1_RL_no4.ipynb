{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (GIF-7005)",
      "language": "python",
      "name": "pycharm-92b34923"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "Devoir1_RL_no4.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-qRGdHmfC7U"
      },
      "source": [
        "import numpy as np\n",
        "from math import*\n",
        "#import matplotlib.pyplot \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import scipy\n",
        "import scipy.stats\n",
        "from numpy import polynomial\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "#from scipy.optimize import NonlinearConstraint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGLsBH77fC7t"
      },
      "source": [
        "class ContextBandit:\n",
        "    \n",
        "    def __init__(self, S_space, X , Theta, sigma,seed=None):\n",
        "        #Attention! X est une liste de longueur K, chaque élément est un tableau donnant les phi(s) pour \n",
        "        #chaque s dans un intervalle des contextes S (ici discrétisé par S_space)\n",
        "        #Theta est un tableau K x d, ou chanque ligne représente les theta permettant de générer la fonction \n",
        "        #f de l'action k.\n",
        "        \n",
        "        self.S_space = np.copy(S_space)\n",
        "        \n",
        "        self.n_S = len(self.S_space)\n",
        "        \n",
        "        self.X = np.copy(X)\n",
        "        \n",
        "        self.Theta = np.copy(Theta)\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        \n",
        "        self.random = np.random.RandomState(seed)\n",
        "        \n",
        "        #Nombre d'actions de l'espace discrétisé\n",
        "        #self.K = X.shape[0]\n",
        "        self.K = Theta.shape[0]\n",
        "        self.d = Theta.shape[1]\n",
        "        \n",
        "        #self.means contiendra les moyennes (f) pour chacune des deux actions\n",
        "        self.means = np.zeros((self.K, self.n_S))\n",
        "        \n",
        "        for i in range(self.K):\n",
        "            self.means[i] = self.X[i].dot(self.Theta[i])\n",
        "        \n",
        "        # pour conserver le regret (indicateur de la performance)\n",
        "        \n",
        "        self.k_star  = np.zeros(self.n_S,dtype=int)\n",
        "        \n",
        "        self.gaps = np.zeros((self.K, self.n_S))\n",
        "        \n",
        "        for i in range(self.n_S):\n",
        "            self.k_star[i] = np.argmax(self.means[:,i])\n",
        "            self.gaps[:,i] = self.means[self.k_star[i],i] - self.means[:,i]\n",
        "        \n",
        "        #self.k_star contient l'action optimale dépendante du contexte\n",
        "        #self.gaps contient les gaps (tableau de dimension K x n_space)\n",
        "        \n",
        "        self.regret = []\n",
        "        \n",
        "    def play(self, k, s):\n",
        "        #joue l'action k au contexte s donnée, Attention, s est un index\n",
        "        self.regret.append(self.gaps[k,s])\n",
        "        \n",
        "        # Reward est la moyenne de l'action k au contexte s plus un bruit gaussien\n",
        "        reward = self.means[k,s] + self.random.normal(0, self.sigma)\n",
        "        \n",
        "        return reward\n",
        "    \n",
        "    def get_cumulative_regret(self):\n",
        "        \n",
        "        return np.cumsum(self.regret)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBD0_pu6fC76"
      },
      "source": [
        "def kernel_ts_sampling_contextuel(bandit, T, Lambda, R, seed=None, plot=False, bw = 1):\n",
        "    '''\n",
        "    Reçoit un bandit contextue, un horizon T\n",
        "    Lambda =...\n",
        "    R = upper bound sur le sigma du bruit\n",
        "    bw = bandwidth pour le noyau RBF du GaussianProcessRegressor\n",
        "    '''\n",
        "    \n",
        "    generation = np.random.RandomState(seed)\n",
        "    \n",
        "    bandwidth = bw\n",
        "    \n",
        "    #On préparer en X et un Y pour chaque bras pour le Gaussianprocess.\n",
        "    X, y = [], []\n",
        "    \n",
        "    for k in range(bandit.K):\n",
        "        X.append([])\n",
        "        y.append([])\n",
        "    \n",
        "    #On doit initialiser un f_hat et un SIGMA_hat pour chacun des k bras\n",
        "    \n",
        "    f_hat = np.ones((bandit.K,bandit.n_S))*7\n",
        "    \n",
        "    SIGMA_hat = []\n",
        "    for k in range(bandit.K):\n",
        "        SIGMA_hat.append([])\n",
        "    \n",
        "    for k in range(bandit.K):\n",
        "       # SIGMA_hat[k] = np.eye(bandit.n_S)\n",
        "        SIGMA_hat[k] = np.zeros((bandit.n_S,bandit.n_S))\n",
        "        \n",
        "    #préparation d'une liste de f_tilde près à recevoir les nombres échantillonnées pour chaque action k\n",
        "    f_tilde = np.zeros((bandit.K,bandit.n_S))\n",
        "    \n",
        "   # for (k in range(bandit.K)):\n",
        "   #     f_tilde.append([])\n",
        "    \n",
        "    for t in range(T):\n",
        "        \n",
        "        #print(t)\n",
        "        #print(X)\n",
        "        \n",
        "        #échantillonner un f_tilde pour chacune des actions.\n",
        "        \n",
        "        for k in range(bandit.K):\n",
        "            f_tilde[k] = generation.multivariate_normal(f_hat[k], SIGMA_hat[k])\n",
        "        \n",
        "        if(plot):\n",
        "            #plt.plot(bandit.S_space, f_tilde[0], color='red', label='action 1')\n",
        "            #plt.plot(bandit.S_space, f_tilde[1], color='blue', label='action 2')\n",
        "            #plt.title(\"Graphiques de la simulation de la fonction f_tilde \\n des rewards après {} tour(s)\".format(t))\n",
        "            plt.plot(bandit.S_space, f_hat[0], color='red', label='action 1')\n",
        "            plt.plot(bandit.S_space, f_hat[1], color='blue', label='action 2')\n",
        "            plt.title(\"Graphiques de la simulation de la fonction f_hat \\n des rewards après {} tour(s)\".format(t))\n",
        "            plt.xlabel('Contexte')\n",
        "            plt.ylabel('Moyenne des rewards')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        \n",
        "        #on génère le contexte aléatoirement, (c'est un index de la discrétisation de l'espace S)\n",
        "        s = generation.randint(low=0,high=bandit.n_S)\n",
        "        \n",
        "        # l'agent infère l'action optimale selon le contexte s\n",
        "        \n",
        "        k_t = np.argmax(f_tilde[:,s])\n",
        "        #print(f_tilde[:,s])\n",
        "        \n",
        "        #l'agent jour l'action qu'il pressent optimale\n",
        "        \n",
        "        y_t = bandit.play(k_t,s)\n",
        "        \n",
        "        # mise à jour du X et du y pour l'action jouée\n",
        "        \n",
        "        X[k_t].append([bandit.S_space[s]])\n",
        "        \n",
        "        #print(t)\n",
        "        #print(k_t)\n",
        "        #print(bandit.S_space[s])\n",
        "        \n",
        "        y[k_t].append(y_t)\n",
        "        \n",
        "        # nouvelle régression pour l'action jouée\n",
        "        X_arr, y_arr = np.array(X[k_t]), np.array(y[k_t])\n",
        "            \n",
        "        model = GaussianProcessRegressor(RBF(length_scale=bandwidth), alpha=Lambda, optimizer=None)\n",
        "        \n",
        "        model.fit(X_arr, y_arr)\n",
        "        \n",
        "        # mise à jour de f_hat et SIGMA_hat pour l'action jouée\n",
        "        \n",
        "        f_hat[k_t], k_lambda = model.predict(bandit.S_space[:, None], return_cov=True)\n",
        "        \n",
        "        SIGMA_hat[k_t] = (R/Lambda)*k_lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl1HqwG4fC8E"
      },
      "source": [
        "#Préparation d'un contexte pour tester l'algorithme de kernel Thompson Sampling sur des bandits contextuels.\n",
        "\n",
        "space = np.linspace(0,1,100)\n",
        "\n",
        "features_1 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "features_2 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "\n",
        "features = [features_1,features_2]\n",
        "\n",
        "random = np.random.RandomState(999)\n",
        "theta_1 = random.uniform(-1,1,6)\n",
        "theta_2 = random.uniform(-1,1,6)\n",
        "\n",
        "\n",
        "theta_1 = theta_1/np.linalg.norm(theta_1,2)\n",
        "theta_2 = theta_2/np.linalg.norm(theta_2,2)\n",
        "\n",
        "Theta=np.array([theta_1,theta_2])\n",
        "\n",
        "sigma = 0.1\n",
        "\n",
        "bandit = ContextBandit(space, features, Theta, sigma, 42)\n",
        "\n",
        "f_1 = np.dot(features[0], Theta[0])\n",
        "f_2 = np.dot(features[1], Theta[1])\n",
        "\n",
        "plt.plot(space,f_1,color='red',label='action 1')\n",
        "plt.plot(space,f_2,color='blue',label='action 2')\n",
        "plt.title('Fonctions donnant la moyenne de reward des actions\\n selon le contexte')\n",
        "plt.xlabel('Contexte')\n",
        "plt.ylabel('moyenne de reward')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#print(bandit.gaps)\n",
        "\n",
        "T=100\n",
        "Lambda=sigma**2\n",
        "R=sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Humh3q9QfC8M"
      },
      "source": [
        "#Test de l'algorithme\n",
        "kernel_ts_sampling_contextuel(bandit, T, Lambda, R, seed=2, plot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgleZodQfC8W"
      },
      "source": [
        "#Préparation d'un contexte pour tester l'algorithme de kernel Thompson Sampling sur des bandits contextuels.\n",
        "\n",
        "space = np.linspace(0,1,100)\n",
        "\n",
        "features_1 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "features_2 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "\n",
        "features = [features_1,features_2]\n",
        "\n",
        "random = np.random.RandomState(999)\n",
        "theta_1 = random.uniform(-1,1,6)\n",
        "theta_2 = random.uniform(-1,1,6)\n",
        "\n",
        "\n",
        "theta_1 = theta_1/np.linalg.norm(theta_1,2)\n",
        "theta_2 = theta_2/np.linalg.norm(theta_2,2)\n",
        "\n",
        "Theta=np.array([theta_1,theta_2])\n",
        "\n",
        "sigma = 0.1\n",
        "\n",
        "bandit = ContextBandit(space, features, Theta, sigma, 42)\n",
        "\n",
        "#print(bandit.gaps)\n",
        "\n",
        "T=1000\n",
        "Lambda=sigma**2\n",
        "R=sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVvsA-e7fC8e"
      },
      "source": [
        "#Test de l'algorithme avec matrice de variances, covariances nulles au départ\n",
        "kernel_ts_sampling_contextuel(bandit, T, Lambda, R, seed=2)\n",
        "\n",
        "plt.plot(bandit.get_cumulative_regret())\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('Pseudo-regret cumulatif')\n",
        "plt.title('Pseudo-regret cumulatif Thompson sampling \\n pour bandit contextuel à 2 bras')\n",
        "#plt.savefig('rapport/figures/pseudo_regret_cumul_context.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSlSyI00fC8k"
      },
      "source": [
        "#Préparation d'un contexte pour tester l'algorithme de kernel Thompson Sampling sur des bandits contextuels.\n",
        "\n",
        "space = np.linspace(0,1,100)\n",
        "\n",
        "features_1 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "features_2 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "\n",
        "features = [features_1,features_2]\n",
        "\n",
        "random = np.random.RandomState(999)\n",
        "\n",
        "bandits = []\n",
        "for i in range(5):\n",
        "    theta_1 = random.uniform(-1,1,6)\n",
        "    theta_2 = random.uniform(-1,1,6)\n",
        "\n",
        "    theta_1 = theta_1/np.linalg.norm(theta_1,2)\n",
        "    theta_2 = theta_2/np.linalg.norm(theta_2,2)\n",
        "\n",
        "    Theta=np.array([theta_1,theta_2])\n",
        "\n",
        "    sigma = 0.1\n",
        "    \n",
        "\n",
        "    bandits.append(ContextBandit(space, features, Theta, sigma, 42))\n",
        "\n",
        "#print(bandit.gaps)\n",
        "\n",
        "T=500\n",
        "Lambda=sigma**2\n",
        "R=sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtRfYm55fC8q"
      },
      "source": [
        "cumul_regret = []\n",
        "for bandit in bandits:\n",
        "    kernel_ts_sampling_contextuel(bandit, T, Lambda, R, seed=2)\n",
        "    cumul_regret.append(bandit.get_cumulative_regret())\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvySm15_fC8w"
      },
      "source": [
        "mean_cumul_regret = np.mean(cumul_regret, axis = 0)\n",
        "plt.plot(mean_cumul_regret)\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('Pseudo-regret cumulatif')\n",
        "plt.title('Pseudo-regret cumulatif Thompson sampling \\n pour bandit contextuel à 2 bras avec bandwidth=1')\n",
        "plt.show()\n",
        "#plt.savefig('rapport/figures/regret_cumul_bw1.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmgVvu-nfC83"
      },
      "source": [
        "#Préparation d'un contexte pour tester l'algorithme de kernel Thompson Sampling sur des bandits contextuels.\n",
        "\n",
        "space = np.linspace(0,1,100)\n",
        "\n",
        "features_1 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "features_2 = np.array([[1, x, x**2, x**3, x**4, x**5] for x in space])\n",
        "\n",
        "features = [features_1,features_2]\n",
        "\n",
        "random = np.random.RandomState(999)\n",
        "\n",
        "bandits = []\n",
        "for i in range(5):\n",
        "    theta_1 = random.uniform(-1,1,6)\n",
        "    theta_2 = random.uniform(-1,1,6)\n",
        "\n",
        "    theta_1 = theta_1/np.linalg.norm(theta_1,2)\n",
        "    theta_2 = theta_2/np.linalg.norm(theta_2,2)\n",
        "\n",
        "    Theta=np.array([theta_1,theta_2])\n",
        "\n",
        "    sigma = 0.1\n",
        "    \n",
        "\n",
        "    bandits.append(ContextBandit(space, features, Theta, sigma, 42))\n",
        "\n",
        "#print(bandit.gaps)\n",
        "\n",
        "T=500\n",
        "Lambda=sigma**2\n",
        "R=sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yWGYGi-fC8-"
      },
      "source": [
        "cumul_regret = []\n",
        "for bandit in bandits:\n",
        "    kernel_ts_sampling_contextuel(bandit, T, Lambda, R, seed=2, bw=2)\n",
        "    cumul_regret.append(bandit.get_cumulative_regret())\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3j3PuvYfC9F"
      },
      "source": [
        "mean_cumul_regret = np.mean(cumul_regret, axis = 0)\n",
        "plt.plot(mean_cumul_regret)\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('Pseudo-regret cumulatif')\n",
        "plt.title('Pseudo-regret cumulatif Thompson sampling \\n pour bandit contextuel à 2 bras avec bandwidth=2')\n",
        "plt.show()\n",
        "#plt.savefig('rapport/figures/regret_cumul_bw2.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiKOIxcYfC9N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}