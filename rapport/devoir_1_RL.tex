\documentclass[letterpaper,11pt]{article}
\usepackage{etex}
\reserveinserts{28}
\usepackage{amssymb}
\usepackage{theorem}
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage{fancybox}
\usepackage{fancyhdr}
\usepackage{tabularx}
\usepackage{color}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage[utf8]{inputenc} % Pour pouvoir taper les accent directement et non pas passer par \'
\usepackage[T1]{fontenc} %%% Pour que les accents soient correctement traités dans le PDF et le DVI
\usepackage{lmodern} %Un autre package pour les accents français
\usepackage[francais]{babel} %Un autre package pour les accents
\usepackage{ifthen}
%\usepackage{multicol}
%\usepackage{cancel}
\usepackage{pst-all}
\usepackage{pstricks-add}
\usepackage{multicol}
%\usepackage{tikz}
%\usepackage{pgf,tikz}
%\usepackage{circuitikz}
%\usetikzlibrary{shapes}
%\usetikzlibrary{calc}
%\usetikzlibrary{plotmarks}
%\usepackage{tkz-fct}
\usepackage{fp}
\usepackage{float}
\usepackage{siunitx}
\usepackage{pdfpages}%Pour sortir seulement certaine pages du pdf
\usepackage{textcomp}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, % make the links colored
    linkcolor=blue, % color TOC links in blue
    urlcolor=red, % color URLs in red
    linktoc=all % 'all' will create links for everything in the TOC
}

\sisetup{locale = FR, number-math-rm, per-mode=symbol, separate-uncertainty}

\renewcommand{\exp}[1]{\mathrm{e}^{#1}}

\setlength{\parindent}{0pt}



\begin{document}

\pagestyle{fancy}
\lhead{IFT-7201}
\chead{Devoir 1 (Automne 2020)}
\rhead{Équipe 10}

%\section{L'énoncé}

%\includepdf{devoir1RotationsFranA2018.pdf}

\section{No 1}

\section{KL UCB}


\subsection{Pseudo-code}
On consid?re un bandit ? $K$ bras sur un horizon de temps de T
\begin{itemize}
\setlength\itemsep{0.2cm}

\item Pour chaque $t\leq K:$

\begin{itemize}

\item $N[t] = N[t]+1$

\item $S[t] = S[t]+Gain(t)$

\end{itemize}

\item Pour chaque $K < t \leq T:$

\begin{itemize}

\item $k_t = amgmax(\ref{eq: ucb_bernoulli})$

\item $N[k_t] = N[k_t]+1$

\item $S[k_t] = S[k_t]+Gain(k_t)$

\end{itemize}


\end{itemize}

\begin{equation}
d(p,q) = p \log \frac{p}{q} + (1-p) \log \frac{1-p}{1-q}
\end{equation}\label{eq: differentien_bernoulli}

\begin{equation}
max \left\{ q \in \Theta : N[a] d\left(\frac{S[a]}{N[a]},q\right) \leq \log(t) + c \log(\log(t)) \right\}
\label{eq: ucb_bernoulli}
\end{equation}

\subsection{Implementation bernoulli}

Pour implementer cet algorithme, on doit utiliser un optimiseur numerique, car il n'existe pas de forme fermée lorsque les recompenses suivent une distrubution bernoulli.
De plus, l'implementation inclu un bris d'egalite.
Ainsi si 2 bras ont le meme UCB et qu'ils representent les bras avec le plus grand UCB alors l'algorithme choisira le bras ayant le plus petit nombre de jeu.

\subsection{Implementation UCB Gaussienne}

Pour l'implementation de l'algorithme UCB gaussien il existe une forme fermee.
Cette forme a ete utilisee dans l'implementation, car elle rend l'exploitation plus rapide, car il n'a pas d'optimisation a faire pour determiner l'UCB.

Pour calculer la borne UCB gaussien, l'ecart-type doit etre connu, mais ce n'est pas le cas pour la configuration de gandit utilise.
L'ecart-type maximale d'une distribution bernoulli est donc utilisee (0.25).

\subsection{Comparaison des modèles}
On peut observer que les deux modèles performent bien sur des bandits bernoulli.
Les deux modèles ont un regret cumulatif sous linéaire, mais le modèle utilsant la borne KL UCB pour bandit bernoulli performe mieux.
Cela peut être dut au fait qu'avec le modèle qui utilise la borne KL UCB pour des bandits gaussien utilise une borne avec une variance de 0.25.
Cette variance est utilisée, car elle représente la variance maximale dans un bandit bernoulli ainsi, elle permet de conserver des garanties.
Par contre l'utilisation de cette borne cause une sur exploration.
On peut observer l'effet de la sur exploration dans \ref{fig: kl_ucb}.
On peut aussi observer que la variance semble un peu plus élevée pour le KL UCB optimisé.
Cela peut être dut au fait que relativement peu d'instances ont été générées.

\includegraphics[scale=0.4]{figures/comparaison.pdf}
\label{fig: kl_ucb}

\section{No 3}

\subsection{Rappel sur la loi de gamma}

$X$ est une variable aléatoire suivant une loi gamma ($X\sim\mathrm{Gamma}(\alpha,\beta)$) si sa fonction de densité est

\begin{equation}
f(x; \alpha,\,\beta) =  
\left\{
\begin{array}{cl}
\dfrac{\beta^{\alpha} x^{\alpha-1} \exp{-\beta x}}{\Gamma(\alpha)} & \text{si } x>0\\[0.4cm]
0 & \text{sinon}
\end{array}
\right.
\end{equation}

où $\alpha>0$ et $\beta>0$ sont des paramètres. \\
Avec cette paramétrisation, l'espérance et la variance de cette loi sont

\begin{eqnarray} 
\mu      &=& \frac{\alpha}{\beta} \label{equation: moyenne gamma}\\
\sigma^2 &=& \frac{\alpha}{\beta^2} \label{equation: variance gamma}
\end{eqnarray}

La loi gamma est asymétrique à droite (asymétrie de $2/\sqrt{\alpha}$).\\
On observe que le système d'équations (\ref{equation: moyenne gamma}) et (\ref{equation: variance gamma}) est équivalent à

\begin{eqnarray}
\alpha   &=& \frac{\mu^2}{\sigma^2} \label{equation: alpha gamma}\\
\beta &=& \frac{\mu}{\sigma^2} \label{equation: beta gamma}
\end{eqnarray}

Cela est utile notamment si l'on souhaite obtenir les paramètres d'une loi gamma étant donnée sa moyenne et sa variance.

\subsection{Rappel sur la loi de Poisson}

La loi de Poisson est une loi de probabilité discrète dont le support est $\mathbb{N}=\left\{0,1,2,3,...\right\}.$\\
On dit que $X$ suit une loi de Poisson ($X\sim\mathrm{Pois}(\lambda)$) si sa fonction de probabilité (fonction de masse) est

\begin{equation*}
f(x; \lambda) = 
\left\{
\begin{array}{cl}
\frac{\exp{-\lambda} \lambda^x}{x\,!} & \text{si } x\in\mathbb{N}\\[0.4cm]
0 & \text{sinon}
\end{array}
\right.
\end{equation*}

où $\lambda$ est un paramètre. L'espérance est $\mu=\lambda$ et la variance $\sigma^2=\lambda.$

\subsection{Algorithme Thomas Sampling pour des bandits à distribution Poisson }

Pour des bandits à distributions de Poisson, c'est-à-dire dans le cas où chaque bras génère un reward selon une loi de Poisson de paramètre $\lambda$ inconnu, le conjugué à utilisé est la loi gamma.\\

Plus précisément, après $n$ observations $x_1,x_2,...,x_n$ tirées d'une loi de Poisson inconnue, la distribution posterior modélisant le paramètre $\lambda$ inconnu sera

\begin{equation}
\mathrm{Gamma}\left(\alpha_0 + \sum_{i=1}^n x_i,\,\beta_0 + n\right)
\end{equation}

où $\alpha_0$ et $\beta_0$ sont les paramètres de la distribution de gamma prior, ils correspondent donc aux paramètres choisis permettant d'initier la distribution.\\

Cela mène au pseudo-code suivant pour un algorithme Thomas Sampling sur des bandits à $K$ bras à distribution de Poisson.

\subsubsection{Pseudo-code}

\begin{itemize}
\setlength\itemsep{0.2cm}

\item
Initialiser une distribution gamma $\pi_k(0)$ pour $k=1,2,...,K$, c'est-à-dire choisir un couple $(\alpha_{k,0}, \beta_{k,0})\, \forall{k}$

\item Pour chaque $t\geq 1:$

\begin{itemize}
\item
Échantillonner un nombre $\theta_{k,t}$ de la distribution $\pi_k(t-1),$ pour $k=1,2,...,K$

\item
Sélectionner $k_t=\underset{k}{\mathrm{argmax}} (\theta_{k,t})$ 

\item
jouer l'action $k_t$ et observer le reward $r_t$ 

\item 
Modifier la posterior $\pi_{k_t}(t)$ de l'action jouée: $\alpha_{k_t} \leftarrow \alpha_{k_t}+ r_t$ et $\beta_{k_t}  \leftarrow \beta_{k_t} + 1$ 

\item
Laisser inchangé les autres posteriors: $\pi_{k}(t) \leftarrow \pi_{k}(t-1),\, \forall k\neq k_t$

\end{itemize}

\end{itemize}

\vspace*{0.2cm}
Remarque: même si ce n'est pas toujours mentionné explicitement dans la suite, les différents bras d'un bandit auront toujours la même paramétrisation de leur distribution prior.

\subsection{Exploration du comportement de l'alogorihme (validation de la fonctionnalité)}

Pour explorer le comportement de l'algorithme et vérifier qu'il fonctionne bien, on propose une expérience. Cette dernière consistera à lancer l'algorithme sur un horizon $T=100$ sur une instance de bandit à deux bras à distribution de Poisson de moyennes respectives $\lambda_1=6,$ $\lambda_2=7$ et avec une paramétrisation prior $\alpha_0=5/2,$ $\beta_0=1/2$ identiques pour les deux bras. Pour tout $t=0,1,...,100,$ on affiche les 2 distributions posteriors. On pourra ainsi voir l'évolution des posteriors selon les pas de temps. Notons qu'ici, on choisit une loi gamma initiale avec $\mu_0=5$ et $\sigma_0^2=10.$ Nous discuterons plus loin du choix de la paramétrisation initiale. La figure \ref{figure: évolution des posteriors} montre le graphiques des densités posteriors après 0 tour (priors), 1 tour, 5 tours, 100 tours. Dans le notebook, l'ensemble des 101 figures sont générées. \\

Initialement, on voit que les deux priors sont superposées. Après un tour, on voit qu'une seule distribution est modifiée (celle de l'action jouée, ici l'action 1). On voit par la suite que les distributions posteriors se déplacent et se concentrent, notamment celle de l'action optimale 2 qui se concentre de plus en plus autour de la moyenne associée à son bras ($\lambda_2=7$) et celle de l'action minimale se concentrant plus à gauche. Le comportement des posteriors est attendu et rassurant. À long terme, à chaque tour, il est de plus en plus probable que l'action jouée soit l'action optimale. 

\begin{figure}[H]
\caption{Évolution des posteriors}
\label{figure: évolution des posteriors}
\begin{center}

\includegraphics[scale=0.45]{posterior_tour0.png} \hfill \includegraphics[scale=0.45]{posterior_tour1.png}

\includegraphics[scale=0.45]{posterior_tour5.png} \hfill \includegraphics[scale=0.45]{posterior_tour100.png}

%\includegraphics[scale=0.5]{posterior_tour100.png}

\end{center}
\end{figure}

\subsection{Expérimentation sur l'algorithme}

Dans cette section, on explore le comportement de l'algorithme dans diverses situations tout en s'efforçant de discuter de la sélection des priors. En effet, la loi de gamma n'ayant aucune paramétrisation la faisant corresponde à une loi uniforme, il faut faire un choix de priors qui n'est pas trivial. Pour ce faire, on supposera ici que l'on ne connaît pas les valeurs de $\lambda$ associée à chaque bras, mais que l'on connaît à tout de moins un intervalle sur lequel ils se trouvent. Dépendant des choix des priors, ces derniers sont des distributions qui peuvent couvrir bien ou non l'intervalle possibles des $\lambda,$ on suspecte que cela aura un effet sur le pseudo-regret cumulatif.\\

Pour établir une prior, il faut établir un couple $\alpha_0,\,\beta_0.$ Nous établirons plutôt un moyenne $(\mu_0)$ et une variance ($\sigma_0^2$) pour cette distribution prior et obtiendrons $\alpha_0$ et $\beta_0$ associées avec les équations (\ref{equation: moyenne gamma}) et (\ref{equation: variance gamma}).

\subsubsection{Effet de la variance de la loi prior}

\subsubsection*{Expérience sur des variances trop petites}

On génère $N=1000$ instances de bandits de Poisson à deux bras.\\
Pour chaque instance, les moyennes $\lambda_1, \lambda_2$ des bras sont tirées aléatoirement d'une loi uniforme continue sur l'intervalle $[0,10]$ pour chaque instance.\\
On considérera le cas ici ou l'agent sait que les moyennes sont dans cet intervalle.\\

Pour chaque couple ($\mu_0,$ $\sigma^2_0,$) suivant:

$$(5,10),\,(5,5),\,(5,1),\,(5,1/2),\,(5,1/4)$$

On trouve $\alpha_0$ et $\beta_0$ associée à l'aide des équations $(\ref{equation: moyenne gamma})$ et $(\ref{equation: variance gamma})$
\\

On fait jouer Thomas sampling sur les $N=1000$ instances sur un horizon $T=1000.$\\
 
On trace les pseudos-regret cumulatif moyen avec une déviation standard au dessus.\\

Notons qu'ici, dans les différents couples $(\mu_0,\sigma^2_0)$ explorés, la moyenne est toujours 5 (le centre de l'intervalle [0,10]) et la variance varie (partant de 10 correspondant à la grandeur de l'intervalle et se rapetissant).\\

La figure suivante montre le résultat obtenu.

\begin{figure}[H]
\label{figure: variance petite}
\caption{Comparaisons de la performance selon des priors de variances plus petites}
\begin{center}
\includegraphics[scale=0.5]{etude_variance_petite.png} 
\end{center}
\end{figure}

On remarque que si la distribution prior est choisie avec une variance trop petite, la distribution prior ne couvre pas suffisamment bien l'intervalle $[0,10],$ et cela semble se traduire par une augmentation du pseudo-regret cumulatif moyen. On remarque qu'il semble y avoir un certaine tolérance sur des variations de $\sigma^2_0$ qui ne changent pas significativement la courbe du pseudo-regret cumulatif moyen. \\

Notez que partout dans les graphiques ci-dessous, la ligne continue représente le pseudo-regret cumulatif moyen alors que la ligne pointillée représente la déviation-standard au dessus associée à ce pseudo-regret cumulatif.

\subsubsection*{Expérience sur des variances trop grandes}

Même méthode que l'expérience 1, mais sur les couples $(\mu_0,\sigma^2_0)$ suivants.

$$(5,10),\,(5,20),\,(5,50),\,(5,100),\,(5,1000)$$

La moyenne des priors est toujours le centre de l'intervalle $[0,10],$ la variance varie (partant de 10 correspondant à la grandeur de l'intervalle et se grandissant).\\

La figure suivante montre le résultat obtenu.

\begin{figure}[H]
\label{figure: variance petite}
\caption{Comparaisons de la performance selon des priors de variances plus grandes}
\begin{center}
\includegraphics[scale=0.5]{etude_variance_grande.png} 
\end{center}
\end{figure}

On peut voir qu'une variance légèrement trog grande n'aura pas beaucoup d'effet sur le regret cumulatif moyen, par contre, une variance excessivement trop grande peut en avoir une considérable. Dans ce cas, la distribution prior sur-couvre grandement l'intervalle [0,10] des valeurs possibles de $\lambda.$ Conséquemment, possiblement que les distributions posteriors ne se concentrent pas suffisamment rapidement pour pouvoir bien cerner les moyennes $\lambda_1$ et $\lambda_2$ des distributions de Poisson des bras.

\subsubsection{Effet de la moyenne de la loi prior avec variance <<bonne>>}

Pour bien pouvoir faire varier les moyennes de la prior choisi, on va ici considérer une situation analogue aux deux premières expériences, mais où l'intervalle sur lequel sont choisis les moyennes $\lambda_1, \lambda_2$ est $[10,20]$ au lieu de $[0,10].$ On effectue la même expérience que si haut, sur les couples  $(\mu_0 ,\sigma^2_0)$ qui suivent.


$$(5,10),\,(12,10),\,(15,10),\,(17,10),\,(25,10)$$

La variance de la prior est fixe égale à la longueur de l'intervalle des valeurs possibles de $\lambda.$\\ 

On obtient la figure suivante

\begin{figure}[H]
\label{figure: moyenne décalée 1}
\caption{Comparaisons de la performance selon des priors de variances égale à la longueur de l'intervalle et de moyennes variables.}
\begin{center}
\includegraphics[scale=0.5]{etude_moyenne_decale_var10.png} 
\end{center}
\end{figure}

On remarque que si la moyenne du prior est fortement décalée du centre de l'intervalle $[10,20]$, cela aura un effet sur la performance de l'algorithme, notamment le cas où $\mu_0=5.$ Lorsque la moyenne $\mu_0$ reste dans l'intervalle $[10,20],$ il semble que le fait que la variance soit bonne (distribution prior qui couvre bien l'intervalle) fait en sorte que l'algorithme reste bon même si $\mu_0$ n'est pas centré.   

\subsubsection{Effet de la moyenne de la loi prior avec variance plus petite}

Même expérience que précédemment, mais avec les couples $(\mu_0,\sigma^2_0)$ qui suivent.

$$(9,3),\,(12,3),\,(15,3),\,(17,3),\,(21,3)$$

Cette fois, la variance est plus petite (3).\\

On obtient la figure suivante

\begin{figure}[H]
\label{figure: moyenne décalée 1}
\caption{Comparaisons de la performance selon des priors de variances égalent à 3 et moyennes variables.}
\begin{center}
\includegraphics[scale=0.5]{etude_moyenne_decale_var3.png} 
\end{center}
\end{figure}

On voit qu'ici, avec une variance des priors plus petite, un même décalage de la moyenne $\mu_0$ par rapport au centre de l'intervalle semble être plus coûteux que dans l'expérience précédente. D'ailleurs, le cas $\mu_0=9$ semble en être un bon exemple car il atteint une regret cumulatif moyen final plus élevé que le cas $\mu_0=5$ dans le cas où la variance était de 10. Conséquemment, si l'information que l'on a sur les $\lambda$ (intervalle de possibilité) n'est pas bonne pour fixer les priors, lancer un tel algorithme avec une variance trop petite peut avoir un impact sur la performance, notamment si par malchance on choisit un prior avec $\mu_0$ décalé du centre du réel intervalle des valeurs possibles de $\lambda.$\\

En conclusion, à la lumière des simulations effectuées, les priors semblent devoir être choisis pour couvrir raisonnablement bien l'intervalle des valeurs possibles de $\lambda.$ On pourrait suggérer de prendre la distribution prior telle que $\mu_0$ est le centre de l'intervalle et $\sigma^2_0$ la longueur de l'intervalle. Selon nos simulations, cela semble être un choix raisonnable.


\end{document}
